{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Giai đoạn 1: Nền tảng cơ bản**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Tensor là gì và tại sao cần học về tensor: ###\n",
    "- Tensor là cấu trúc dữ liệu cơ bản trong PyTorch, tương tự như NumPy array nhưng được tối ưu cho deep learning\n",
    "- Tensor có thể chạy trên GPU để tăng tốc độ tính toán\n",
    "- Tensor tự động tính được đạo hàm (gradient) - rất quan trọng trong quá trình huấn luyện neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Các cách tạo tensor cơ bản: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5293, 0.5100, 0.8884, 0.5631],\n",
      "        [0.8076, 0.6140, 0.0794, 0.1053],\n",
      "        [0.7795, 0.0860, 0.1649, 0.8359]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Tạo tensor từ list\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Tạo tensor với giá trị ngẫu nhiên\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "print(random_tensor)\n",
    "\n",
    "# Tạo tensor toàn số 0 hoặc 1\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "ones = torch.ones(size=(3, 4))\n",
    "eye = torch.eye(3)\n",
    "print(zeros)\n",
    "print(ones)\n",
    "print(eye)\n",
    "\n",
    "# Tạo tensor với giá trị tuần tự\n",
    "range_tensor = torch.arange(start=0, end=10, step=2)\n",
    "linspace_tensor = torch.linspace(start=0.1, end=1, steps=10)\n",
    "print(range_tensor)\n",
    "print(linspace_tensor)\n",
    "\n",
    "# Tạo tensor với shape giống tensor khác\n",
    "x_ones = torch.ones_like(x)\n",
    "x_zeros = torch.zeros_like(x)\n",
    "print(x_ones)\n",
    "print(x_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Các thuộc tính quan trọng của tensor: ###\n",
    "- shape: kích thước của tensor\n",
    "- dtype: kiểu dữ liệu (float32, int64,...)\n",
    "- device: tensor được lưu ở đâu (CPU hay GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.int64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ kiểm tra thuộc tính\n",
    "print(x.shape)      # Kích thước\n",
    "print(x.dtype)      # Kiểu dữ liệu\n",
    "print(x.device)     # Thiết bị lưu tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Các phép toán tensor cơ bản: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "new_shape = (2, 5)\n",
    "\n",
    "# Phép cộng\n",
    "result = tensor1 + tensor2\n",
    "# hoặc\n",
    "result = torch.add(tensor1, tensor2)\n",
    "\n",
    "# Phép nhân ma trận\n",
    "result = torch.matmul(tensor1, tensor2)\n",
    "# hoặc\n",
    "result = tensor1 @ tensor2\n",
    "\n",
    "# Reshape tensor\n",
    "reshaped = tensor.reshape(new_shape)\n",
    "# hoặc\n",
    "reshaped = tensor.view(new_shape)\n",
    "\n",
    "print(reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Các thao tác tensor nâng cao: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([[3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([ 9, 10])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# Indexing\n",
    "print(tensor[0])          # Phần tử đầu tiên\n",
    "print(tensor[1:4])       # Slice tensor\n",
    "print(tensor[4])        # Phần tử thứ 5\n",
    "\n",
    "# Concatenate tensors\n",
    "concat = torch.cat([tensor1, tensor2], dim=0)\n",
    "print(concat)\n",
    "\n",
    "# Stack tensors\n",
    "stacked = torch.stack([tensor1, tensor2], dim=0)\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Chuyển đổi giữa các kiểu dữ liệu: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển từ NumPy sang PyTorch\n",
    "numpy_array = np.array([1, 2, 3])\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "# Chuyển từ PyTorch sang NumPy\n",
    "numpy_array = torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Chuyển đổi CPU và GPU: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các lớp Layer trong Neural Network\n",
    "\n",
    "## 1. Fully Connected Layer (Linear Layer)\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X \\in \\mathbb{R}^{n \\times d_{in}}$ (n là số lượng mẫu, $d_{in}$ là số chiều đầu vào)\n",
    "- **Output**: $Y = XW + b \\in \\mathbb{R}^{n \\times d_{out}}$ ($d_{out}$ là số chiều đầu ra)\n",
    "\n",
    "### Tham số\n",
    "- **Weights** ($W \\in \\mathbb{R}^{d_{in} \\times d_{out}}$): Ma trận trọng số\n",
    "- **Bias** ($b \\in \\mathbb{R}^{d_{out}}$): Vector độ lệch\n",
    "- Tổng số tham số: $d_{in} \\times d_{out} + d_{out}$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Thực hiện phép biến đổi tuyến tính từ không gian đầu vào sang không gian đầu ra\n",
    "- Mỗi neuron ở lớp đầu ra kết nối với tất cả các neuron ở lớp đầu vào\n",
    "- Không có chia sẻ tham số\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Nên dùng khi cần mô hình hóa mối quan hệ phức tạp giữa tất cả các đặc trưng đầu vào\n",
    "- Thường dùng ở lớp cuối cùng để ánh xạ đặc trưng sang không gian output (phân loại, hồi quy)\n",
    "\n",
    "### Hạn chế\n",
    "- Số lượng tham số lớn, dễ bị overfitting với dữ liệu lớn\n",
    "- Không có tính chất bất biến với vị trí (không phù hợp cho dữ liệu có cấu trúc như ảnh, văn bản)\n",
    "- Mất thông tin không gian/thứ tự của dữ liệu đầu vào\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Trong MLP (Multilayer Perceptron) cho các bài toán phân loại đơn giản\n",
    "- Kết hợp với các layer khác trong các kiến trúc mạng phức tạp\n",
    "- Lớp cuối cùng trong hầu hết các mô hình deep learning\n",
    "\n",
    "## 2. Convolutional Layer (Conv2D)\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X \\in \\mathbb{R}^{n \\times c_{in} \\times h_{in} \\times w_{in}}$ (n: batch size, $c_{in}$: số kênh đầu vào, $h_{in}, w_{in}$: chiều cao, rộng)\n",
    "- **Output**: $Y \\in \\mathbb{R}^{n \\times c_{out} \\times h_{out} \\times w_{out}}$\n",
    "- Với:\n",
    "  - $h_{out} = \\lfloor \\frac{h_{in} + 2p - k}{s} + 1 \\rfloor$\n",
    "  - $w_{out} = \\lfloor \\frac{w_{in} + 2p - k}{s} + 1 \\rfloor$\n",
    "  - (p: padding, k: kernel size, s: stride)\n",
    "\n",
    "### Tham số\n",
    "- **Kernels/Filters** ($W \\in \\mathbb{R}^{c_{out} \\times c_{in} \\times k \\times k}$): Bộ lọc tích chập\n",
    "- **Bias** ($b \\in \\mathbb{R}^{c_{out}}$): Vector độ lệch cho mỗi kênh đầu ra\n",
    "- Tổng số tham số: $c_{out} \\times c_{in} \\times k \\times k + c_{out}$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Thực hiện tích chập giữa kernel và vùng cục bộ của dữ liệu đầu vào\n",
    "- Di chuyển kernel theo stride, tính tổng tích chập tại mỗi vị trí\n",
    "- Chia sẻ trọng số: cùng một kernel được sử dụng trên toàn bộ ảnh đầu vào\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Với dữ liệu có tính chất không gian như ảnh, video\n",
    "- Khi cần trích xuất đặc trưng cục bộ và giữ lại thông tin không gian\n",
    "- Khi muốn giảm số lượng tham số so với Fully Connected\n",
    "\n",
    "### Hạn chế\n",
    "- Có thể mất thông tin tổng thể/toàn cục trong dữ liệu\n",
    "- Khó mô hình hóa mối quan hệ giữa các vùng xa nhau trong ảnh\n",
    "- Không hiệu quả với dữ liệu không có tính chất không gian\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Computer Vision: phân loại ảnh, phát hiện đối tượng, phân đoạn ảnh\n",
    "- Xử lý tín hiệu thời gian 1D (Conv1D cho dữ liệu âm thanh, EEG)\n",
    "- NLP: tích chập trong văn bản để trích xuất n-grams\n",
    "\n",
    "## 3. Recurrent Neural Network (RNN Layer)\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X = (x_1, x_2, ..., x_T) \\in \\mathbb{R}^{T \\times d_{in}}$ (T: độ dài chuỗi, $d_{in}$: chiều đầu vào)\n",
    "- **Output**: $H = (h_1, h_2, ..., h_T) \\in \\mathbb{R}^{T \\times d_{hidden}}$\n",
    "- Công thức cập nhật: $h_t = \\tanh(W_{ih} x_t + W_{hh} h_{t-1} + b_h)$\n",
    "\n",
    "### Tham số\n",
    "- **Input weights** ($W_{ih} \\in \\mathbb{R}^{d_{in} \\times d_{hidden}}$): Trọng số đầu vào\n",
    "- **Hidden weights** ($W_{hh} \\in \\mathbb{R}^{d_{hidden} \\times d_{hidden}}$): Trọng số trạng thái ẩn\n",
    "- **Bias** ($b_h \\in \\mathbb{R}^{d_{hidden}}$): Độ lệch\n",
    "- Tổng số tham số: $d_{in} \\times d_{hidden} + d_{hidden} \\times d_{hidden} + d_{hidden}$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Xử lý dữ liệu tuần tự, một phần tử một thời điểm\n",
    "- Duy trì trạng thái ẩn chứa thông tin từ các phần tử trước đó\n",
    "- Chia sẻ tham số theo thời gian: cùng một bộ tham số được áp dụng tại mỗi bước thời gian\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Với dữ liệu tuần tự như văn bản, chuỗi thời gian, âm thanh\n",
    "- Khi cần mô hình hóa phụ thuộc thời gian và ngữ cảnh\n",
    "\n",
    "### Hạn chế\n",
    "- Vấn đề gradient biến mất/bùng nổ khi chuỗi dài\n",
    "- Khó nắm bắt phụ thuộc dài hạn\n",
    "- Tính toán tuần tự không tận dụng được tính song song\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- NLP: phân tích cảm xúc, sinh văn bản (trước khi Transformer phổ biến)\n",
    "- Phân tích chuỗi thời gian: dự báo, phát hiện bất thường\n",
    "- Nhận dạng giọng nói, máy dịch tuần tự\n",
    "\n",
    "## 4. LSTM Layer (Long Short-Term Memory)\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X = (x_1, x_2, ..., x_T) \\in \\mathbb{R}^{T \\times d_{in}}$\n",
    "- **Output**: $H = (h_1, h_2, ..., h_T) \\in \\mathbb{R}^{T \\times d_{hidden}}$\n",
    "- **Công thức cập nhật**:\n",
    "  - Forget gate: $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$\n",
    "  - Input gate: $i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$\n",
    "  - Cell candidate: $\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$\n",
    "  - Cell state: $C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t$\n",
    "  - Output gate: $o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$\n",
    "  - Hidden state: $h_t = o_t \\odot \\tanh(C_t)$\n",
    "\n",
    "### Tham số\n",
    "- Weights cho 4 cổng: $W_f, W_i, W_C, W_o \\in \\mathbb{R}^{(d_{in} + d_{hidden}) \\times d_{hidden}}$\n",
    "- Bias cho 4 cổng: $b_f, b_i, b_C, b_o \\in \\mathbb{R}^{d_{hidden}}$\n",
    "- Tổng số tham số: $4 \\times [(d_{in} + d_{hidden}) \\times d_{hidden} + d_{hidden}]$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Mở rộng RNN với cơ chế cổng (gates) để kiểm soát luồng thông tin\n",
    "- Cell state hoạt động như một băng chuyền thông tin, cho phép thông tin chảy qua mạng không bị ảnh hưởng\n",
    "- Các cổng quyết định thông tin nào nên được quên (forget), ghi nhớ (input), và xuất ra (output)\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Khi cần mô hình hóa phụ thuộc dài hạn trong dữ liệu tuần tự\n",
    "- Thay thế RNN thông thường để tránh vấn đề gradient biến mất\n",
    "\n",
    "### Hạn chế\n",
    "- Tính toán phức tạp hơn RNN thông thường\n",
    "- Vẫn có vấn đề với chuỗi rất dài\n",
    "- Tính toán tuần tự khó song song hóa\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Máy dịch, tóm tắt văn bản\n",
    "- Dự báo chuỗi thời gian phức tạp\n",
    "- Sinh nhạc, văn bản dài\n",
    "- Mô hình hóa hành vi người dùng theo thời gian\n",
    "\n",
    "## 5. Self-Attention Layer\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X \\in \\mathbb{R}^{n \\times d_{model}}$ (n: số token, $d_{model}$: chiều của mỗi token)\n",
    "- **Output**: $Y \\in \\mathbb{R}^{n \\times d_{model}}$\n",
    "- **Công thức**:\n",
    "  - Queries: $Q = XW^Q \\in \\mathbb{R}^{n \\times d_k}$\n",
    "  - Keys: $K = XW^K \\in \\mathbb{R}^{n \\times d_k}$\n",
    "  - Values: $V = XW^V \\in \\mathbb{R}^{n \\times d_v}$\n",
    "  - Attention scores: $A = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}}) \\in \\mathbb{R}^{n \\times n}$\n",
    "  - Output: $Y = AV \\in \\mathbb{R}^{n \\times d_v}$\n",
    "\n",
    "### Tham số\n",
    "- **Query weights**: $W^Q \\in \\mathbb{R}^{d_{model} \\times d_k}$\n",
    "- **Key weights**: $W^K \\in \\mathbb{R}^{d_{model} \\times d_k}$\n",
    "- **Value weights**: $W^V \\in \\mathbb{R}^{d_{model} \\times d_v}$\n",
    "- Tổng số tham số: $d_{model} \\times d_k + d_{model} \\times d_k + d_{model} \\times d_v$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Mỗi phần tử tương tác với tất cả các phần tử khác để nắm bắt mối quan hệ toàn cục\n",
    "- Ma trận attention scores thể hiện mức độ liên quan giữa các cặp phần tử\n",
    "- Đầu ra của mỗi vị trí là tổng có trọng số của các giá trị value, với trọng số là attention score\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Khi cần mô hình hóa mối quan hệ toàn cục giữa các phần tử trong chuỗi\n",
    "- Khi dữ liệu có cấu trúc phức tạp không tuần tự\n",
    "\n",
    "### Hạn chế\n",
    "- Độ phức tạp tính toán và bộ nhớ là O(n²) với n là độ dài chuỗi\n",
    "- Không hiệu quả với chuỗi rất dài\n",
    "- Cần kết hợp với positional encoding để nắm bắt thông tin vị trí\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- NLP: mô hình Transformer cho máy dịch, tóm tắt, Q&A\n",
    "- Computer Vision: Vision Transformer (ViT) cho phân loại ảnh, phát hiện đối tượng\n",
    "- Multimodal: kết hợp thông tin từ nhiều modalites (text-image trong CLIP)\n",
    "\n",
    "## 6. Multi-Head Attention Layer\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X \\in \\mathbb{R}^{n \\times d_{model}}$ (n: số token, $d_{model}$: chiều của mỗi token)\n",
    "- **Output**: $Y \\in \\mathbb{R}^{n \\times d_{model}}$\n",
    "- **Công thức**:\n",
    "  - Đối với mỗi head i từ 1 đến h:\n",
    "    - $Q_i = XW_i^Q \\in \\mathbb{R}^{n \\times d_k}$\n",
    "    - $K_i = XW_i^K \\in \\mathbb{R}^{n \\times d_k}$\n",
    "    - $V_i = XW_i^V \\in \\mathbb{R}^{n \\times d_v}$\n",
    "    - $\\text{head}_i = \\text{Attention}(Q_i, K_i, V_i) \\in \\mathbb{R}^{n \\times d_v}$\n",
    "  - Nối các heads: $\\text{MultiHead} = \\text{Concat}(\\text{head}_1, ..., \\text{head}_h) \\in \\mathbb{R}^{n \\times (h \\times d_v)}$\n",
    "  - Đầu ra cuối cùng: $Y = \\text{MultiHead}W^O \\in \\mathbb{R}^{n \\times d_{model}}$\n",
    "\n",
    "### Tham số\n",
    "- **Query weights** cho h heads: $W_i^Q \\in \\mathbb{R}^{d_{model} \\times d_k}$ (i từ 1 đến h)\n",
    "- **Key weights** cho h heads: $W_i^K \\in \\mathbb{R}^{d_{model} \\times d_k}$ (i từ 1 đến h)\n",
    "- **Value weights** cho h heads: $W_i^V \\in \\mathbb{R}^{d_{model} \\times d_v}$ (i từ 1 đến h)\n",
    "- **Output weights**: $W^O \\in \\mathbb{R}^{(h \\times d_v) \\times d_{model}}$\n",
    "- Tổng số tham số: $h \\times (d_{model} \\times d_k + d_{model} \\times d_k + d_{model} \\times d_v) + (h \\times d_v) \\times d_{model}$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Chạy h cơ chế self-attention song song, mỗi cơ chế có các tham số riêng\n",
    "- Mỗi head có thể tập trung vào các khía cạnh khác nhau của mối quan hệ (ngữ pháp, ngữ nghĩa, etc.)\n",
    "- Kết quả từ tất cả các heads được kết hợp thông qua một phép chiếu tuyến tính\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Khi cần nắm bắt các loại mối quan hệ phức tạp trong dữ liệu\n",
    "- Cốt lõi của các mô hình Transformer hiện đại\n",
    "\n",
    "### Hạn chế\n",
    "- Độ phức tạp tính toán và bộ nhớ cao (vẫn là O(n²))\n",
    "- Số lượng tham số lớn\n",
    "- Cần kỹ thuật như Sparse Attention để xử lý chuỗi dài\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Các mô hình ngôn ngữ lớn (GPT, BERT, LLaMA)\n",
    "- Vision Transformers đạt SOTA trong Computer Vision\n",
    "- Mô hình đa phương thức (CLIP, Flamingo)\n",
    "\n",
    "## 7. Embedding Layer\n",
    "\n",
    "### Công thức\n",
    "- **Input**: Chỉ số nguyên $i \\in \\{0, 1, 2, ..., V-1\\}$ (V: kích thước từ điển)\n",
    "- **Output**: Vector nhúng $e_i \\in \\mathbb{R}^d$ (d: chiều nhúng)\n",
    "\n",
    "### Tham số\n",
    "- **Embedding matrix**: $E \\in \\mathbb{R}^{V \\times d}$ (V: kích thước từ điển, d: chiều nhúng)\n",
    "- Tổng số tham số: $V \\times d$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Ánh xạ các giá trị rời rạc (như token, từ, ký tự) sang không gian vector liên tục\n",
    "- Hoạt động như một bảng tra cứu: chỉ số i tra cứu hàng thứ i trong ma trận embedding\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Với dữ liệu rời rạc, phân loại như từ, ký tự, ID người dùng, ID sản phẩm\n",
    "- Khi muốn biểu diễn các đối tượng rời rạc trong không gian liên tục để xử lý bằng mạng neural\n",
    "\n",
    "### Hạn chế\n",
    "- Số lượng tham số lớn với từ điển lớn\n",
    "- Không chia sẻ thông tin giữa các token hiếm\n",
    "- Cần kỹ thuật như subword tokenization để xử lý OOV (out-of-vocabulary)\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- NLP: nhúng từ và token cho mọi mô hình ngôn ngữ\n",
    "- Hệ thống gợi ý: nhúng ID người dùng và sản phẩm\n",
    "- Knowledge Graph: nhúng thực thể và quan hệ\n",
    "\n",
    "## 8. Layer Normalization\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $x \\in \\mathbb{R}^{n \\times d}$ (n: batch size, d: số chiều đặc trưng)\n",
    "- **Output**: $y \\in \\mathbb{R}^{n \\times d}$\n",
    "- **Công thức**:\n",
    "  - Tính mean và variance cho mỗi mẫu dọc theo chiều đặc trưng:\n",
    "    - $\\mu_i = \\frac{1}{d}\\sum_{j=1}^{d}x_{ij}$\n",
    "    - $\\sigma_i^2 = \\frac{1}{d}\\sum_{j=1}^{d}(x_{ij} - \\mu_i)^2$\n",
    "  - Chuẩn hóa: $\\hat{x}_{ij} = \\frac{x_{ij} - \\mu_i}{\\sqrt{\\sigma_i^2 + \\epsilon}}$\n",
    "  - Scale và shift: $y_{ij} = \\gamma \\cdot \\hat{x}_{ij} + \\beta$\n",
    "\n",
    "### Tham số\n",
    "- **Scale** ($\\gamma \\in \\mathbb{R}^d$): Hệ số tỷ lệ cho mỗi đặc trưng\n",
    "- **Shift** ($\\beta \\in \\mathbb{R}^d$): Hệ số dịch chuyển cho mỗi đặc trưng\n",
    "- Tổng số tham số: $2 \\times d$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Chuẩn hóa đặc trưng theo mỗi mẫu riêng lẻ (không phải theo batch như Batch Normalization)\n",
    "- Giúp ổn định quá trình học trong các mạng sâu\n",
    "- Giảm thiểu sự phụ thuộc vào kích thước batch\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Trong các mô hình Transformer và RNN\n",
    "- Khi batch size nhỏ\n",
    "- Khi muốn chuẩn hóa đặc trưng mà không bị ảnh hưởng bởi các mẫu khác trong batch\n",
    "\n",
    "### Hạn chế\n",
    "- Có thể kém hiệu quả hơn Batch Normalization trong một số trường hợp CNN\n",
    "- Thêm chi phí tính toán\n",
    "- Không cung cấp hiệu ứng regularization như Batch Normalization\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Các mô hình Transformer trong NLP (GPT, BERT)\n",
    "- Vision Transformer trong Computer Vision\n",
    "- Mô hình RNN/LSTM khi train với chuỗi có độ dài khác nhau\n",
    "\n",
    "## 9. Dropout Layer\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $x \\in \\mathbb{R}^{n \\times d}$ (n: batch size, d: số chiều đặc trưng)\n",
    "- **Output**: $y \\in \\mathbb{R}^{n \\times d}$\n",
    "- **Công thức**:\n",
    "  - Trong quá trình huấn luyện:\n",
    "    - Generate mask: $m_{ij} \\sim \\text{Bernoulli}(p)$ (p: xác suất giữ lại)\n",
    "    - Áp dụng mask và scale: $y_{ij} = \\frac{m_{ij} \\cdot x_{ij}}{p}$\n",
    "  - Trong quá trình suy luận: $y_{ij} = x_{ij}$\n",
    "\n",
    "### Tham số\n",
    "- **Dropout rate** (1-p): Xác suất một neuron bị \"drop\"\n",
    "- Tổng số tham số: 0 (không có tham số có thể học)\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Trong quá trình huấn luyện, ngẫu nhiên \"tắt\" một tỷ lệ các neuron\n",
    "- Scale các neuron còn lại để bảo toàn giá trị mong đợi của đầu ra\n",
    "- Trong quá trình suy luận, sử dụng tất cả các neuron mà không áp dụng dropout\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Khi muốn ngăn overfitting trong mô hình lớn\n",
    "- Giữa các lớp fully connected\n",
    "- Trong các mô hình với nhiều tham số\n",
    "\n",
    "### Hạn chế\n",
    "- Có thể làm chậm quá trình hội tụ\n",
    "- Yêu cầu model lớn hơn để đạt hiệu quả tốt\n",
    "- Không hiệu quả trong một số kiến trúc hiện đại với normalization tốt\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Regularization trong hầu hết các loại mạng neural\n",
    "- MLP và fully connected layers\n",
    "- Giữa các layer trong RNN/LSTM để tránh overfitting\n",
    "\n",
    "## 10. Pooling Layers (Max Pooling, Average Pooling)\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X \\in \\mathbb{R}^{n \\times c \\times h \\times w}$ (n: batch size, c: số kênh, h,w: chiều cao, rộng)\n",
    "- **Output**: $Y \\in \\mathbb{R}^{n \\times c \\times h_{out} \\times w_{out}}$\n",
    "- **Công thức Max Pooling**:\n",
    "  - $Y_{i,j,k,l} = \\max_{0 \\leq m < k_h, 0 \\leq n < k_w} X_{i,j,k \\times s_h + m, l \\times s_w + n}$\n",
    "- **Công thức Average Pooling**:\n",
    "  - $Y_{i,j,k,l} = \\frac{1}{k_h \\times k_w}\\sum_{m=0}^{k_h-1}\\sum_{n=0}^{k_w-1} X_{i,j,k \\times s_h + m, l \\times s_w + n}$\n",
    "\n",
    "### Tham số\n",
    "- **Kernel size** ($k_h, k_w$): Kích thước cửa sổ pooling\n",
    "- **Stride** ($s_h, s_w$): Bước nhảy giữa các cửa sổ pooling\n",
    "- **Padding** (p): Đệm thêm xung quanh đầu vào\n",
    "- Tổng số tham số: 0 (không có tham số có thể học)\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- **Max Pooling**: Chọn giá trị lớn nhất trong mỗi cửa sổ\n",
    "- **Average Pooling**: Tính trung bình các giá trị trong mỗi cửa sổ\n",
    "- Giảm kích thước không gian của đầu vào, giữ lại thông tin quan trọng\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- **Max Pooling**: Khi muốn giữ lại các đặc trưng nổi bật (edges, textures)\n",
    "- **Average Pooling**: Khi muốn giữ thông tin background và texture tổng thể\n",
    "- Khi muốn giảm kích thước feature map và số lượng tham số trong mạng\n",
    "\n",
    "### Hạn chế\n",
    "- Mất thông tin không gian chính xác\n",
    "- Không có tham số có thể học\n",
    "- Các kiến trúc hiện đại (như ResNet) thường thay thế bằng convolution với stride>1\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- CNN truyền thống (LeNet, AlexNet, VGG)\n",
    "- Max Pooling: phát hiện đối tượng, trích xuất đặc trưng cục bộ\n",
    "- Average Pooling: phân loại toàn cục (Global Average Pooling trong NIN, ResNet)\n",
    "\n",
    "## 11. Batch Normalization Layer\n",
    "\n",
    "### Công thức\n",
    "- **Input**: $X \\in \\mathbb{R}^{n \\times d}$ (n: batch size, d: số chiều đặc trưng)\n",
    "- **Output**: $Y \\in \\mathbb{R}^{n \\times d}$\n",
    "- **Công thức**:\n",
    "  - Tính mean và variance theo batch cho mỗi đặc trưng:\n",
    "    - $\\mu_j = \\frac{1}{n}\\sum_{i=1}^{n}x_{ij}$\n",
    "    - $\\sigma_j^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_{ij} - \\mu_j)^2$\n",
    "  - Chuẩn hóa: $\\hat{x}_{ij} = \\frac{x_{ij} - \\mu_j}{\\sqrt{\\sigma_j^2 + \\epsilon}}$\n",
    "  - Scale và shift: $y_{ij} = \\gamma_j \\cdot \\hat{x}_{ij} + \\beta_j$\n",
    "  - Trong quá trình suy luận, sử dụng mean và variance running:\n",
    "    - $\\hat{x}_{ij} = \\frac{x_{ij} - E[\\mu_j]}{\\sqrt{E[\\sigma_j^2] + \\epsilon}}$\n",
    "\n",
    "### Tham số\n",
    "- **Scale** ($\\gamma \\in \\mathbb{R}^d$): Hệ số tỷ lệ cho mỗi đặc trưng\n",
    "- **Shift** ($\\beta \\in \\mathbb{R}^d$): Hệ số dịch chuyển cho mỗi đặc trưng\n",
    "- **Running mean** và **Running variance** (được cập nhật trong quá trình huấn luyện)\n",
    "- Tổng số tham số có thể học: $2 \\times d$\n",
    "\n",
    "### Cơ chế hoạt động\n",
    "- Chuẩn hóa đầu vào của mỗi layer để có mean=0, variance=1 theo batch\n",
    "- Giảm thiểu \"internal covariate shift\" - sự thay đổi phân phối đặc trưng trong quá trình huấn luyện\n",
    "- Cho phép sử dụng learning rate lớn hơn và initialization ít nhạy cảm hơn\n",
    "\n",
    "### Nên dùng khi nào\n",
    "- Trong các mạng CNN sâu\n",
    "- Khi batch size đủ lớn (thường ≥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
