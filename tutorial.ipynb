{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Giai đoạn 1: Nền tảng cơ bản**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Tensor là gì và tại sao cần học về tensor: ###\n",
    "- Tensor là cấu trúc dữ liệu cơ bản trong PyTorch, tương tự như NumPy array nhưng được tối ưu cho deep learning\n",
    "- Tensor có thể chạy trên GPU để tăng tốc độ tính toán\n",
    "- Tensor tự động tính được đạo hàm (gradient) - rất quan trọng trong quá trình huấn luyện neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Các cách tạo tensor cơ bản: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5293, 0.5100, 0.8884, 0.5631],\n",
      "        [0.8076, 0.6140, 0.0794, 0.1053],\n",
      "        [0.7795, 0.0860, 0.1649, 0.8359]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([0, 2, 4, 6, 8])\n",
      "tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
      "        1.0000])\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Tạo tensor từ list\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Tạo tensor với giá trị ngẫu nhiên\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "print(random_tensor)\n",
    "\n",
    "# Tạo tensor toàn số 0 hoặc 1\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "ones = torch.ones(size=(3, 4))\n",
    "eye = torch.eye(3)\n",
    "print(zeros)\n",
    "print(ones)\n",
    "print(eye)\n",
    "\n",
    "# Tạo tensor với giá trị tuần tự\n",
    "range_tensor = torch.arange(start=0, end=10, step=2)\n",
    "linspace_tensor = torch.linspace(start=0.1, end=1, steps=10)\n",
    "print(range_tensor)\n",
    "print(linspace_tensor)\n",
    "\n",
    "# Tạo tensor với shape giống tensor khác\n",
    "x_ones = torch.ones_like(x)\n",
    "x_zeros = torch.zeros_like(x)\n",
    "print(x_ones)\n",
    "print(x_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Các thuộc tính quan trọng của tensor: ###\n",
    "- shape: kích thước của tensor\n",
    "- dtype: kiểu dữ liệu (float32, int64,...)\n",
    "- device: tensor được lưu ở đâu (CPU hay GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.int64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ kiểm tra thuộc tính\n",
    "print(x.shape)      # Kích thước\n",
    "print(x.dtype)      # Kiểu dữ liệu\n",
    "print(x.device)     # Thiết bị lưu tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Các phép toán tensor cơ bản: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "\n",
    "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "new_shape = (2, 5)\n",
    "\n",
    "# Phép cộng\n",
    "result = tensor1 + tensor2\n",
    "# hoặc\n",
    "result = torch.add(tensor1, tensor2)\n",
    "\n",
    "# Phép nhân ma trận\n",
    "result = torch.matmul(tensor1, tensor2)\n",
    "# hoặc\n",
    "result = tensor1 @ tensor2\n",
    "\n",
    "# Reshape tensor\n",
    "reshaped = tensor.reshape(new_shape)\n",
    "# hoặc\n",
    "reshaped = tensor.view(new_shape)\n",
    "\n",
    "print(reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Các thao tác tensor nâng cao: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([[3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([ 9, 10])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n"
     ]
    }
   ],
   "source": [
    "# Indexing\n",
    "print(tensor[0])          # Phần tử đầu tiên\n",
    "print(tensor[1:4])       # Slice tensor\n",
    "print(tensor[4])        # Phần tử thứ 5\n",
    "\n",
    "# Concatenate tensors\n",
    "concat = torch.cat([tensor1, tensor2], dim=0)\n",
    "print(concat)\n",
    "\n",
    "# Stack tensors\n",
    "stacked = torch.stack([tensor1, tensor2], dim=0)\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Chuyển đổi giữa các kiểu dữ liệu: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển từ NumPy sang PyTorch\n",
    "numpy_array = np.array([1, 2, 3])\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "# Chuyển từ PyTorch sang NumPy\n",
    "numpy_array = torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Chuyển đổi CPU và GPU: ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các lớp Layer trong Neural Network - Phân tích chi tiết\n",
    "\n",
    "## 1. Fully Connected Layer (Dense Layer)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Tensor $X$ có kích thước $(batch\\_size, input\\_features)$\n",
    "- **Output**: $Y = \\sigma(W \\cdot X + b)$ có kích thước $(batch\\_size, output\\_features)$\n",
    "\n",
    "**Tham số**:\n",
    "- Ma trận trọng số $W$ có kích thước $(input\\_features, output\\_features)$\n",
    "- Bias $b$ có kích thước $(output\\_features)$\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Mỗi neuron nhận input từ tất cả các neuron ở layer trước đó\n",
    "- Tính tổng có trọng số của tất cả các inputs, cộng với bias\n",
    "- Áp dụng hàm kích hoạt $\\sigma$ lên kết quả\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Các bài toán cần tính toán trên dữ liệu vector hóa\n",
    "- Layer cuối cùng trong hầu hết mạng neural để đưa ra dự đoán\n",
    "\n",
    "**Hạn chế**:\n",
    "- Số lượng tham số lớn: $input\\_features \\times output\\_features + output\\_features$\n",
    "- Không giữ được thông tin không gian/vị trí trong dữ liệu\n",
    "- Dễ bị overfitting khi dữ liệu ít\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Phân loại đơn giản trên dữ liệu vector\n",
    "- Layer cuối trong bài toán hồi quy/phân loại\n",
    "- MLP (Multi-Layer Perceptron) cho dữ liệu có cấu trúc bảng\n",
    "\n",
    "## 2. Convolutional Layer (Conv2D)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Tensor $X$ có kích thước $(batch\\_size, height, width, channels\\_in)$\n",
    "- **Output**: $Y$ có kích thước $(batch\\_size, height', width', channels\\_out)$\n",
    "\n",
    "**Tham số**:\n",
    "- Bộ lọc (filters/kernels): $K$ có kích thước $(kernel\\_size, kernel\\_size, channels\\_in, channels\\_out)$\n",
    "- Bias: $b$ có kích thước $(channels\\_out)$\n",
    "- Stride: Bước nhảy của cửa sổ tích chập\n",
    "- Padding: Đệm zero xung quanh input\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Mỗi filter trượt trên input, tính tích chập (dot product)\n",
    "- Mỗi vị trí trượt tạo ra một giá trị đầu ra\n",
    "- Kết quả đầu ra mỗi filter tạo thành một feature map\n",
    "- Nhiều filter tạo ra nhiều feature map (channels)\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Dữ liệu có cấu trúc không gian (ảnh, time series, audio)\n",
    "- Khi cần phát hiện đặc trưng cục bộ, giữ thông tin vị trí\n",
    "\n",
    "**Hạn chế**:\n",
    "- Chỉ bắt được đặc trưng cục bộ, không nắm bắt mối quan hệ toàn cục\n",
    "- Khó khăn với input có kích thước không đều\n",
    "- Thiếu tính bất biến theo phép quay (rotation invariance)\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Xử lý ảnh, nhận dạng đối tượng\n",
    "- Phân tích time series/1D convolutional\n",
    "- Phát hiện đặc trưng trong xử lý ngôn ngữ tự nhiên\n",
    "\n",
    "## 3. Recurrent Layer (RNN/LSTM/GRU)\n",
    "\n",
    "### 3.1 Simple RNN\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Chuỗi $X = [x_1, x_2, ..., x_t]$ với mỗi $x_i$ có kích thước $(batch\\_size, features)$\n",
    "- **Output**: $h_t = \\sigma(W_{hx} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b_h)$\n",
    "\n",
    "**Tham số**:\n",
    "- $W_{hx}$: Ma trận trọng số từ input đến hidden state\n",
    "- $W_{hh}$: Ma trận trọng số từ hidden state hiện tại đến hidden state tiếp theo\n",
    "- $b_h$: Bias\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Duy trì một hidden state $h$ qua các bước thời gian\n",
    "- Tại mỗi bước t, kết hợp input hiện tại $x_t$ với hidden state trước đó $h_{t-1}$\n",
    "- Áp dụng hàm kích hoạt (thường là tanh) lên kết quả\n",
    "\n",
    "### 3.2 LSTM (Long Short-Term Memory)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Chuỗi $X = [x_1, x_2, ..., x_t]$\n",
    "- **Output**: Hidden states $h_t$ và cell states $c_t$\n",
    "- Các cổng: forget gate $(f_t)$, input gate $(i_t)$, output gate $(o_t)$, và cell candidate $(g_t)$\n",
    "\n",
    "$$f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$$\n",
    "$$i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$$\n",
    "$$g_t = \\tanh(W_g \\cdot [h_{t-1}, x_t] + b_g)$$\n",
    "$$o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$$\n",
    "$$c_t = f_t \\odot c_{t-1} + i_t \\odot g_t$$\n",
    "$$h_t = o_t \\odot \\tanh(c_t)$$\n",
    "\n",
    "**Tham số**:\n",
    "- $W_f, W_i, W_g, W_o$: Ma trận trọng số cho mỗi cổng\n",
    "- $b_f, b_i, b_g, b_o$: Bias cho mỗi cổng\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Sử dụng cơ chế cổng (gates) để kiểm soát thông tin\n",
    "- Forget gate quyết định bỏ đi thông tin nào từ cell state\n",
    "- Input gate quyết định cập nhật thông tin nào vào cell state\n",
    "- Output gate kiểm soát thông tin nào từ cell state đưa ra ngoài\n",
    "\n",
    "**Khi nào nên dùng (RNN/LSTM/GRU)**:\n",
    "- Dữ liệu dạng chuỗi (văn bản, time series, audio)\n",
    "- Khi cần nắm bắt phụ thuộc dài hạn trong dữ liệu\n",
    "- Các tác vụ có tính tuần tự và phụ thuộc thời gian\n",
    "\n",
    "**Hạn chế**:\n",
    "- Tính toán tuần tự, khó song song hóa\n",
    "- Vấn đề gradient biến mất/bùng nổ trong RNN đơn giản\n",
    "- Tốn kém tính toán cho chuỗi dài (LSTM/GRU đỡ hơn)\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Xử lý ngôn ngữ tự nhiên, dịch máy\n",
    "- Dự báo chuỗi thời gian, phân tích tài chính\n",
    "- Phân tích cảm xúc, sinh văn bản\n",
    "\n",
    "## 4. Pooling Layer\n",
    "\n",
    "### 4.1 Max Pooling\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Tensor $X$ có kích thước $(batch\\_size, height, width, channels)$\n",
    "- **Output**: $Y$ có kích thước $(batch\\_size, height/pool\\_size, width/pool\\_size, channels)$\n",
    "- $Y_{i,j,c} = \\max_{m,n \\in window} X_{stride \\cdot i + m, stride \\cdot j + n, c}$\n",
    "\n",
    "**Tham số**:\n",
    "- Pool size: Kích thước cửa sổ gộp (thường là 2x2)\n",
    "- Stride: Bước nhảy (thường bằng pool size)\n",
    "- Padding: Đệm zero (thường không dùng)\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Chia input thành các cửa sổ không chồng chéo\n",
    "- Lấy giá trị lớn nhất trong mỗi cửa sổ\n",
    "- Giảm kích thước không gian nhưng giữ nguyên số channels\n",
    "\n",
    "### 4.2 Average Pooling\n",
    "\n",
    "**Công thức**:\n",
    "- Tương tự Max Pooling, nhưng lấy giá trị trung bình thay vì giá trị lớn nhất\n",
    "- $Y_{i,j,c} = \\frac{1}{|window|} \\sum_{m,n \\in window} X_{stride \\cdot i + m, stride \\cdot j + n, c}$\n",
    "\n",
    "**Khi nào nên dùng (Pooling)**:\n",
    "- Sau các lớp Convolutional để giảm kích thước không gian\n",
    "- Khi muốn tính bất biến với dịch chuyển nhỏ (translation invariance)\n",
    "- Giảm tham số và tính toán trong mạng\n",
    "\n",
    "**Hạn chế**:\n",
    "- Mất thông tin vị trí chi tiết\n",
    "- Không có tham số để học (fixed operation)\n",
    "- Có thể bỏ qua đặc trưng quan trọng (với Max Pooling)\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- CNN cho phân loại ảnh\n",
    "- Giảm chiều không gian và tránh overfitting\n",
    "- Max Pooling tốt cho việc phát hiện đặc trưng; Average Pooling tốt cho tổng hợp tổng thể\n",
    "\n",
    "## 5. Normalization Layers\n",
    "\n",
    "### 5.1 Batch Normalization\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $X$ với kích thước $(batch\\_size, features)$ hoặc $(batch\\_size, height, width, channels)$\n",
    "- **Output**: $Y = \\gamma \\cdot \\frac{X - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}} + \\beta$\n",
    "\n",
    "**Tham số**:\n",
    "- $\\gamma$: Tham số scale (có thể học)\n",
    "- $\\beta$: Tham số shift (có thể học)\n",
    "- $\\epsilon$: Hằng số nhỏ để ổn định phép chia\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tính trung bình $\\mu_B$ và phương sai $\\sigma_B^2$ trên mỗi batch\n",
    "- Chuẩn hóa input để có trung bình 0, phương sai 1\n",
    "- Scale và shift bằng các tham số có thể học $\\gamma$ và $\\beta$\n",
    "\n",
    "### 5.2 Layer Normalization\n",
    "\n",
    "**Công thức**:\n",
    "- Tương tự Batch Normalization, nhưng chuẩn hóa theo các features thay vì theo batch\n",
    "- Tính $\\mu$ và $\\sigma$ trên mỗi sample riêng biệt\n",
    "\n",
    "**Khi nào nên dùng (Normalization)**:\n",
    "- Batch Norm: Mạng CNN, mạng feed-forward sâu\n",
    "- Layer Norm: Mạng RNN, Transformer\n",
    "- Khi cần tăng tốc độ hội tụ và ổn định quá trình huấn luyện\n",
    "\n",
    "**Hạn chế**:\n",
    "- Batch Norm phụ thuộc vào kích thước batch\n",
    "- Tăng độ phức tạp tính toán\n",
    "- Có thể làm giảm khả năng biểu diễn của mô hình nếu sử dụng không đúng cách\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Batch Norm: ResNet, GoogleNet và hầu hết CNN hiện đại\n",
    "- Layer Norm: BERT, GPT, Transformer và mạng NLP tiên tiến\n",
    "- Instance/Group Norm: StyleGAN và mạng sinh ảnh\n",
    "\n",
    "## 6. Dropout Layer\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $X$ bất kỳ\n",
    "- **Output (khi training)**: $Y = X \\odot M / (1-p)$ với $M$ là mask nhị phân với xác suất $p$ để có giá trị 0\n",
    "- **Output (khi inference)**: $Y = X$ (không áp dụng dropout khi dự đoán)\n",
    "\n",
    "**Tham số**:\n",
    "- Dropout rate $p$: Xác suất một neuron bị \"tắt\"\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Trong quá trình huấn luyện, ngẫu nhiên \"tắt\" một tỷ lệ neuron\n",
    "- Scale lại các neuron còn lại để tổng đầu ra không đổi\n",
    "- Khi dự đoán, sử dụng tất cả các neuron\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Khi có nguy cơ overfitting (mô hình lớn, dữ liệu ít)\n",
    "- Giữa các lớp fully connected\n",
    "- Trong các mạng RNN (nhưng cần thận trọng)\n",
    "\n",
    "**Hạn chế**:\n",
    "- Làm chậm quá trình hội tụ, cần nhiều epochs hơn\n",
    "- Không hiệu quả với các mô hình nhỏ hoặc underfitting\n",
    "- Cần điều chỉnh learning rate đi kèm\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Các mô hình phân loại lớn\n",
    "- Transfer learning khi fine-tuning\n",
    "- Ensemble learning (mỗi forward pass với dropout là một mô hình khác nhau)\n",
    "\n",
    "## 7. Attention Layer\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Queries $Q$, Keys $K$, Values $V$\n",
    "- **Output**: $\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n",
    "\n",
    "**Tham số**:\n",
    "- Chiều của query/key/value\n",
    "- Số lượng heads (với multi-head attention)\n",
    "- Projection matrices $W_Q, W_K, W_V, W_O$\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tính độ tương đồng giữa query và mỗi key\n",
    "- Áp dụng softmax để chuẩn hóa trọng số\n",
    "- Tính tổng có trọng số của các value dựa trên trọng số\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Mô hình cần nắm bắt mối quan hệ dài hạn trong dữ liệu\n",
    "- Khi cần tập trung vào các phần khác nhau của input\n",
    "- Thay thế cơ chế tuần tự của RNN\n",
    "\n",
    "**Hạn chế**:\n",
    "- Độ phức tạp O(n²) theo độ dài chuỗi\n",
    "- Tốn kém bộ nhớ cho chuỗi dài\n",
    "- Cần kỹ thuật để áp dụng hiệu quả với input lớn\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Kiến trúc Transformer (BERT, GPT, T5)\n",
    "- Dịch máy, tóm tắt văn bản\n",
    "- Vision Transformer (ViT) trong xử lý ảnh\n",
    "\n",
    "## 8. Embedding Layer\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: Chỉ số nguyên $i$ (hoặc tensor chỉ số)\n",
    "- **Output**: Vector $v_i$ từ ma trận embedding\n",
    "\n",
    "**Tham số**:\n",
    "- Ma trận embedding $E$ có kích thước $(vocab\\_size, embedding\\_dim)$\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Mỗi chỉ số đầu vào được ánh xạ tới một hàng trong ma trận embedding\n",
    "- Thực chất là một lookup table có thể cập nhật\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Biểu diễn dữ liệu rời rạc (từ, token, category) bằng vector liên tục\n",
    "- Đầu vào cho các mô hình NLP\n",
    "- Encoding categorical features\n",
    "\n",
    "**Hạn chế**:\n",
    "- Số lượng tham số lớn với vocab lớn\n",
    "- Cần đủ dữ liệu để học biểu diễn tốt\n",
    "- Thách thức với từ hiếm/không có trong vocabulary\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Word embedding trong NLP (Word2Vec, GloVe)\n",
    "- Mô hình ngôn ngữ, dịch máy\n",
    "- Recommender systems (user/item embeddings)\n",
    "\n",
    "## 9. Residual Connections (ResNet Block)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $X$\n",
    "- **Output**: $Y = X + F(X)$ với $F$ là một chuỗi các layer (thường là Conv + BN + ReLU)\n",
    "\n",
    "**Tham số**:\n",
    "- Tham số của các layer trong hàm $F$\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tạo đường tắt (shortcut connection) bỏ qua một hoặc nhiều layer\n",
    "- Cộng đầu ra của các layer này với input ban đầu\n",
    "- Giúp gradient flow dễ dàng hơn qua mạng\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Mạng neural sâu (>10 layers)\n",
    "- Khi gặp vấn đề vanishing gradient\n",
    "- Cải thiện hiệu suất mô hình sâu\n",
    "\n",
    "**Hạn chế**:\n",
    "- Tăng nhẹ độ phức tạp trong triển khai\n",
    "- Cần điều chỉnh chiều nếu input và output có kích thước khác nhau\n",
    "- Có thể không cần thiết cho mạng nông\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- ResNet và các biến thể (ResNeXt, DenseNet)\n",
    "- Vision Transformer với residual connections\n",
    "- Kiến trúc Transformer trong NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các Activation Function trong Neural Network\n",
    "\n",
    "## 1. Sigmoid (Logistic)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\sigma(x) = \\frac{1}{1 + e^{-x}} \\in (0,1)$\n",
    "- **Đạo hàm**: $\\sigma'(x) = \\sigma(x)(1-\\sigma(x))$\n",
    "\n",
    "**Tham số**: Không có tham số có thể điều chỉnh\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Biến đổi giá trị đầu vào thành giá trị trong khoảng (0,1)\n",
    "- Đồ thị hình chữ S (S-shaped)\n",
    "- Bão hòa và tiệm cận đến 0 hoặc 1 với đầu vào âm hoặc dương lớn\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Layer cuối cùng trong bài toán phân loại nhị phân\n",
    "- Mô hình hóa xác suất\n",
    "- Các cổng trong LSTM (kết hợp với tanh)\n",
    "\n",
    "**Hạn chế**:\n",
    "- Vấn đề gradient biến mất (vanishing gradient) với đầu vào có giá trị tuyệt đối lớn\n",
    "- Output không zero-centered, làm chậm quá trình học\n",
    "- Đạo hàm tối đa là 0.25, làm chậm quá trình hội tụ\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Mô hình hồi quy logistic\n",
    "- Cơ chế cổng trong LSTM và GRU\n",
    "- Bài toán phân loại nhị phân\n",
    "\n",
    "## 2. Tanh (Hyperbolic Tangent)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} = \\frac{2}{1 + e^{-2x}} - 1 \\in (-1,1)$\n",
    "- **Đạo hàm**: $\\tanh'(x) = 1 - \\tanh^2(x)$\n",
    "\n",
    "**Tham số**: Không có tham số có thể điều chỉnh\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Biến đổi giá trị đầu vào thành giá trị trong khoảng (-1,1)\n",
    "- Tương tự sigmoid nhưng zero-centered\n",
    "- Bão hòa và tiệm cận đến -1 hoặc 1 với đầu vào âm hoặc dương lớn\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Khi cần outputs zero-centered\n",
    "- Trong mạng RNN, LSTM\n",
    "- Khi đầu vào đã được chuẩn hóa\n",
    "\n",
    "**Hạn chế**:\n",
    "- Vẫn gặp vấn đề gradient biến mất với đầu vào có giá trị tuyệt đối lớn\n",
    "- Tính toán phức tạp hơn so với ReLU\n",
    "- Chậm hơn ReLU trong quá trình huấn luyện\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Mạng RNN cổ điển\n",
    "- Các mô hình xử lý chuỗi thời gian\n",
    "- Mô hình hóa giá trị tiếp theo trong dãy với khoảng giá trị cố định\n",
    "\n",
    "## 3. ReLU (Rectified Linear Unit)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{ReLU}(x) = \\max(0, x) \\in [0, \\infty)$\n",
    "- **Đạo hàm**: $\\text{ReLU}'(x) = \\begin{cases} 1 & \\text{if } x > 0 \\\\ 0 & \\text{if } x \\leq 0 \\end{cases}$\n",
    "\n",
    "**Tham số**: Không có tham số có thể điều chỉnh\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Đầu ra bằng 0 với đầu vào âm\n",
    "- Đầu ra bằng đầu vào với đầu vào dương\n",
    "- Đơn giản, hiệu quả tính toán cao\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Layer ẩn trong hầu hết các mạng CNN, MLP hiện đại\n",
    "- Khi cần tốc độ tính toán cao\n",
    "- Mạng sâu với nhiều layer\n",
    "\n",
    "**Hạn chế**:\n",
    "- \"Dying ReLU\" - neuron có thể \"chết\" khi gradient = 0 với x ≤ 0\n",
    "- Không zero-centered, có thể gây ra hiện tượng zigzag khi cập nhật\n",
    "- Không giới hạn trên, có thể gây mất ổn định trong quá trình học\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- CNN cho nhận dạng ảnh\n",
    "- Mạng deep feed-forward\n",
    "- Hầu hết các kiến trúc deep learning hiện đại\n",
    "\n",
    "## 4. Leaky ReLU\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{LeakyReLU}(x) = \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha x & \\text{if } x \\leq 0 \\end{cases} \\in \\mathbb{R}$\n",
    "- **Đạo hàm**: $\\text{LeakyReLU}'(x) = \\begin{cases} 1 & \\text{if } x > 0 \\\\ \\alpha & \\text{if } x \\leq 0 \\end{cases}$\n",
    "\n",
    "**Tham số**: \n",
    "- $\\alpha$: hệ số độ dốc cho x < 0 (thường là 0.01)\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tương tự ReLU nhưng cho phép gradient nhỏ (alpha) cho đầu vào âm\n",
    "- Giải quyết vấn đề \"dying ReLU\"\n",
    "- Vẫn hiệu quả về mặt tính toán\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Thay thế ReLU khi gặp vấn đề dying neurons\n",
    "- Khi muốn tận dụng thông tin từ giá trị âm\n",
    "- Trong các mạng GAN\n",
    "\n",
    "**Hạn chế**:\n",
    "- Thêm một hyperparameter (alpha) cần tinh chỉnh\n",
    "- Vẫn không zero-centered\n",
    "- Cải thiện không đáng kể trong một số trường hợp\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Mạng GAN (Generative Adversarial Networks)\n",
    "- Thay thế ReLU trong CNN\n",
    "- Các mô hình học sâu với negative features quan trọng\n",
    "\n",
    "## 5. Parametric ReLU (PReLU)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{PReLU}(x) = \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha_i x & \\text{if } x \\leq 0 \\end{cases}$\n",
    "- **Đạo hàm**: $\\text{PReLU}'(x) = \\begin{cases} 1 & \\text{if } x > 0 \\\\ \\alpha_i & \\text{if } x \\leq 0 \\end{cases}$\n",
    "\n",
    "**Tham số**: \n",
    "- $\\alpha_i$: tham số có thể học cho mỗi kênh hoặc mỗi neuron\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tương tự Leaky ReLU nhưng $\\alpha$ là tham số có thể học\n",
    "- Model tự tìm giá trị tối ưu cho $\\alpha$\n",
    "- Có thể có $\\alpha$ khác nhau cho mỗi kênh/neuron\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Khi muốn mô hình tự tìm slope tối ưu cho giá trị âm\n",
    "- Trong các mạng CNN sâu\n",
    "- Khi có đủ dữ liệu để học tham số thêm\n",
    "\n",
    "**Hạn chế**:\n",
    "- Tăng số lượng tham số, có thể gây overfitting với dữ liệu ít\n",
    "- Cần kỹ thuật regularization tốt\n",
    "- Tính toán phức tạp hơn ReLU thông thường\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Mạng CNN cho nhận dạng ảnh (ResNet)\n",
    "- Mô hình với dữ liệu lớn\n",
    "- Transfer learning\n",
    "\n",
    "## 6. ELU (Exponential Linear Unit)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{ELU}(x) = \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha (e^x - 1) & \\text{if } x \\leq 0 \\end{cases}$\n",
    "- **Đạo hàm**: $\\text{ELU}'(x) = \\begin{cases} 1 & \\text{if } x > 0 \\\\ \\alpha e^x & \\text{if } x \\leq 0 \\end{cases}$\n",
    "\n",
    "**Tham số**: \n",
    "- $\\alpha$: kiểm soát giá trị tiệm cận cho x âm (thường là 1.0)\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tương tự ReLU cho x > 0\n",
    "- Có giá trị âm bão hòa (-α) cho x âm lớn\n",
    "- Đạo hàm mượt ở mọi điểm (không như ReLU)\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Khi cần tốc độ hội tụ nhanh hơn\n",
    "- Khi muốn giảm thiểu bias shift\n",
    "- Khi muốn đạo hàm liên tục tại x = 0\n",
    "\n",
    "**Hạn chế**:\n",
    "- Tính toán phức tạp hơn ReLU (hàm mũ)\n",
    "- Giá trị alpha cần được chọn trước\n",
    "- Có thể chậm hơn trên GPU\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Mạng CNN sâu\n",
    "- Mạng RNN cải tiến\n",
    "- Bài toán có nhiễu hoặc cần regularization tốt\n",
    "\n",
    "## 7. SELU (Scaled Exponential Linear Unit)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{SELU}(x) = \\lambda \\begin{cases} x & \\text{if } x > 0 \\\\ \\alpha (e^x - 1) & \\text{if } x \\leq 0 \\end{cases}$\n",
    "- **Đạo hàm**: $\\text{SELU}'(x) = \\lambda \\begin{cases} 1 & \\text{if } x > 0 \\\\ \\alpha e^x & \\text{if } x \\leq 0 \\end{cases}$\n",
    "\n",
    "**Tham số**: \n",
    "- $\\lambda \\approx 1.0507$ và $\\alpha \\approx 1.6733$ (được tính toán trước)\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Tương tự ELU nhưng với hệ số scale $\\lambda$\n",
    "- Được thiết kế để tự chuẩn hóa (self-normalizing)\n",
    "- Giữ mean=0 và variance=1 qua các layer\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Mạng feed-forward sâu không sử dụng batch normalization\n",
    "- Khi cần self-normalization\n",
    "- Đầu vào đã được chuẩn hóa\n",
    "\n",
    "**Hạn chế**:\n",
    "- Yêu cầu khởi tạo trọng số đặc biệt (LeCun initialization)\n",
    "- Không phù hợp với mọi kiến trúc (đặc biệt là CNN)\n",
    "- Cần đầu vào được chuẩn hóa tốt\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Mạng feed-forward sâu\n",
    "- Mô hình không sử dụng batch normalization\n",
    "- Bài toán với dữ liệu đã chuẩn hóa tốt\n",
    "\n",
    "## 8. Swish\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{Swish}(x) = x \\cdot \\sigma(\\beta x) = \\frac{x}{1 + e^{-\\beta x}} \\in \\mathbb{R}$\n",
    "- **Đạo hàm**: $\\text{Swish}'(x) = \\beta \\cdot \\text{Swish}(x) + \\sigma(\\beta x)(1 - \\beta \\cdot \\text{Swish}(x))$\n",
    "\n",
    "**Tham số**: \n",
    "- $\\beta$: tham số điều chỉnh (có thể cố định = 1 hoặc là tham số có thể học)\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Kết hợp đặc tính của ReLU và sigmoid\n",
    "- Không bão hòa với đầu vào dương lớn như ReLU\n",
    "- Cho phép gradient nhỏ với đầu vào âm\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Mạng neural rất sâu\n",
    "- Thay thế ReLU trong mạng CNN hiện đại\n",
    "- Khi muốn hiệu suất tốt nhất mà không quan tâm đến tính đơn giản\n",
    "\n",
    "**Hạn chế**:\n",
    "- Tính toán phức tạp hơn ReLU\n",
    "- Đạo hàm phức tạp\n",
    "- Cần thử nghiệm để xác định lợi ích (không phải lúc nào cũng tốt hơn ReLU)\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- CNN hiện đại (EfficientNet)\n",
    "- Mạng neural sâu\n",
    "- Các bài toán cạnh tranh về accuracy\n",
    "\n",
    "## 9. Softmax\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: vector $\\mathbf{z} = (z_1, z_2, ..., z_n) \\in \\mathbb{R}^n$\n",
    "- **Output**: vector $\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}} \\in (0,1)$ với $\\sum_{i=1}^{n} \\sigma(\\mathbf{z})_i = 1$\n",
    "- **Đạo hàm**: $\\frac{\\partial \\sigma(\\mathbf{z})_i}{\\partial z_j} = \\sigma(\\mathbf{z})_i(\\delta_{ij} - \\sigma(\\mathbf{z})_j)$\n",
    "\n",
    "**Tham số**: Không có tham số có thể điều chỉnh\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Chuyển đổi vector thành phân phối xác suất\n",
    "- Tổng tất cả các phần tử output bằng 1\n",
    "- Nhấn mạnh giá trị lớn nhất (winner-take-most)\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Layer cuối cùng trong bài toán phân loại đa lớp\n",
    "- Khi cần biểu diễn dưới dạng xác suất\n",
    "- Attention mechanisms\n",
    "\n",
    "**Hạn chế**:\n",
    "- Không phù hợp cho layer ẩn\n",
    "- Tính toán có thể không ổn định với đầu vào lớn (cần kỹ thuật log-sum-exp)\n",
    "- Toàn bộ outputs phụ thuộc vào mọi input (thay đổi một input ảnh hưởng tất cả outputs)\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- Phân loại đa lớp\n",
    "- Mô hình ngôn ngữ\n",
    "- Cơ chế attention trong Transformer\n",
    "\n",
    "## 10. GELU (Gaussian Error Linear Unit)\n",
    "\n",
    "**Công thức**:\n",
    "- **Input**: $x \\in \\mathbb{R}$\n",
    "- **Output**: $\\text{GELU}(x) = x \\cdot \\Phi(x) = x \\cdot \\frac{1}{2}(1 + \\text{erf}(\\frac{x}{\\sqrt{2}})) \\approx 0.5x(1 + \\tanh(\\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3)))$\n",
    "- **Đạo hàm**: Phức tạp, thường được tính bằng tự động vi phân\n",
    "\n",
    "**Tham số**: Không có tham số có thể điều chỉnh\n",
    "\n",
    "**Cơ chế hoạt động**:\n",
    "- Kết hợp tính chất của ReLU và dropout\n",
    "- Nhân đầu vào với xác suất cumulative từ phân phối Gaussian\n",
    "- Mượt hơn ReLU và nhẹ nhàng hơn khi x < 0\n",
    "\n",
    "**Khi nào nên dùng**:\n",
    "- Mô hình ngôn ngữ lớn\n",
    "- Transformer và các kiến trúc tương tự\n",
    "- Thay thế ReLU/LeakyReLU trong các mạng sâu\n",
    "\n",
    "**Hạn chế**:\n",
    "- Tính toán phức tạp hơn ReLU\n",
    "- Độ cải thiện có thể không đáng kể trong một số trường hợp\n",
    "- Xấp xỉ được sử dụng trong thực tế có thể không chính xác hoàn toàn\n",
    "\n",
    "**Ứng dụng mạnh mẽ**:\n",
    "- BERT, GPT và các mô hình Transformer\n",
    "- Mạng neural lớn và sâu\n",
    "- Các bài toán xử lý ngôn ngữ tự nhiên hiện đại\n",
    "\n",
    "## So sánh và lựa chọn Activation Function\n",
    "\n",
    "### Bảng tổng hợp\n",
    "\n",
    "| Activation Function | Range | Đạo hàm tại x=0 | Zero-centered | Tính toán | Vanishing Gradient | Dying Neuron |\n",
    "|---------------------|-------|----------------|---------------|-----------|-------------------|--------------|\n",
    "| Sigmoid | (0, 1) | 0.25 | Không | Trung bình | Có | Không |\n",
    "| Tanh | (-1, 1) | 1 | Có | Trung bình | Có | Không |\n",
    "| ReLU | [0, ∞) | Không định nghĩa | Không | Nhanh | Không (x>0) | Có |\n",
    "| Leaky ReLU | ℝ | Không định nghĩa | Không | Nhanh | Hiếm | Hiếm |\n",
    "| PReLU | ℝ | Không định nghĩa | Không | Nhanh | Hiếm | Hiếm |\n",
    "| ELU | (-α, ∞) | α | Gần | Trung bình | Hiếm | Không |\n",
    "| SELU | (-λα, ∞) | λα | Đúng* | Trung bình | Không* | Không |\n",
    "| Swish | ℝ | 0.5 | Gần | Chậm | Hiếm | Không |\n",
    "| GELU | ℝ | 0 | Gần | Chậm | Hiếm | Không |\n",
    "| Softmax | (0, 1) | Varies | Không | Chậm | N/A | N/A |\n",
    "\n",
    "*: Với khởi tạo và sử dụng đúng cách\n",
    "\n",
    "### Hướng dẫn lựa chọn\n",
    "\n",
    "1. **Cho layer output**:\n",
    "   - **Phân loại nhị phân**: Sigmoid\n",
    "   - **Phân loại đa lớp**: Softmax\n",
    "   - **Hồi quy với giá trị không giới hạn**: Linear\n",
    "   - **Hồi quy với giá trị dương**: ReLU\n",
    "\n",
    "2. **Cho layer ẩn**:\n",
    "   - **Mặc định/general**: ReLU hoặc Leaky ReLU\n",
    "   - **CNN**: ReLU, Leaky ReLU, Swish\n",
    "   - **RNN**: Tanh, LSTM/GRU gates: Sigmoid\n",
    "   - **Transformer**: GELU \n",
    "   - **FNN sâu không có BN**: SELU\n",
    "   - **Muốn mạng tự tối ưu**: PReLU\n",
    "   \n",
    "3. **Theo tác vụ**:\n",
    "   - **Nhận dạng ảnh**: ReLU, Leaky ReLU, Swish\n",
    "   - **NLP**: GELU, ReLU, ELU\n",
    "   - **Chuỗi thời gian**: Tanh, LSTM/GRU\n",
    "   - **Hồi quy**: ReLU, ELU, Leaky ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các Mô hình Neural Network\n",
    "\n",
    "## 1. Mạng Perceptron Đa lớp (Multi-Layer Perceptron - MLP)\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Input layer → Hidden layer(s) → Output layer\n",
    "- **Kết nối**: Fully connected giữa các layer liên tiếp\n",
    "- **Activation**: ReLU, Sigmoid, Tanh cho hidden layers; Softmax/Sigmoid cho output layer\n",
    "- **Độ phức tạp**: O(n²) với n là số neuron trung bình mỗi layer\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Mỗi neuron áp dụng phép biến đổi tuyến tính (wx + b) rồi qua activation function\n",
    "- Học thông qua backpropagation và gradient descent\n",
    "- Khả năng xấp xỉ hàm đa dạng theo Universal Approximation Theorem\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Dữ liệu có cấu trúc bảng (tabular data)\n",
    "  - Số lượng features vừa phải\n",
    "  - Bài toán phân loại/hồi quy đơn giản đến trung bình\n",
    "  - Cần mô hình dễ triển khai, nhẹ\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Không hiệu quả với dữ liệu có cấu trúc không gian (ảnh, âm thanh)\n",
    "  - Dễ overfitting với dữ liệu kích thước lớn\n",
    "  - Khó mở rộng với số lượng features cực lớn\n",
    "  - Không nắm bắt được quan hệ thời gian/không gian\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Phân loại/hồi quy trên dữ liệu có cấu trúc bảng\n",
    "- Dự đoán tín dụng, phát hiện gian lận\n",
    "- Layer cuối trong các mô hình phức tạp hơn\n",
    "- Embedding học máy cổ điển\n",
    "\n",
    "## 2. Mạng Tích chập (Convolutional Neural Network - CNN)\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Convolutional layers → Pooling layers → Fully connected layers\n",
    "- **Thành phần chính**: \n",
    "  - Convolutional layers: áp dụng bộ lọc trên vùng cục bộ\n",
    "  - Pooling layers: giảm kích thước không gian (max/average pooling)\n",
    "  - Fully connected layers: phân loại dựa trên features đã trích xuất\n",
    "- **Biến thể hiện đại**: ResNet, Inception, EfficientNet, ConvNeXt\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Sử dụng phép tích chập (convolution) để trích xuất đặc trưng cục bộ\n",
    "- Tận dụng tính chất bất biến với dịch chuyển (translation invariance)\n",
    "- Chia sẻ tham số (parameter sharing) giảm số lượng tham số cần học\n",
    "- Trích xuất đặc trưng theo hệ thống phân cấp (hierarchical feature extraction)\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Dữ liệu có cấu trúc không gian (ảnh, video, tín hiệu 1D/2D/3D)\n",
    "  - Các pattern cục bộ quan trọng\n",
    "  - Cần khai thác thông tin không gian\n",
    "  - Khối lượng dữ liệu lớn\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Đòi hỏi nhiều dữ liệu để tránh overfitting\n",
    "  - Tốn kém tính toán cho hình ảnh kích thước lớn\n",
    "  - Khó nắm bắt mối quan hệ toàn cục trong ảnh\n",
    "  - Thiếu đặc tính bất biến với phép quay, tỷ lệ\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Nhận dạng ảnh và phân loại\n",
    "- Phát hiện đối tượng (object detection)\n",
    "- Phân đoạn ảnh (image segmentation)\n",
    "- Xử lý ngôn ngữ tự nhiên (trước Transformer)\n",
    "- Phân tích chuỗi thời gian, tín hiệu y sinh\n",
    "\n",
    "## 3. Mạng Hồi quy (Recurrent Neural Network - RNN)\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Cells có kết nối hồi tiếp (feedback connections)\n",
    "- **Biến thể quan trọng**:\n",
    "  - LSTM (Long Short-Term Memory): giải quyết vấn đề vanishing gradient\n",
    "  - GRU (Gated Recurrent Unit): phiên bản nhẹ hơn của LSTM\n",
    "  - Bidirectional RNN: xử lý chuỗi theo cả hai chiều\n",
    "  - Deep RNN: xếp chồng nhiều layer RNN\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Duy trì trạng thái ẩn (hidden state) qua các bước thời gian\n",
    "- LSTM/GRU sử dụng cơ chế cổng (gates) để kiểm soát luồng thông tin\n",
    "- Cho phép mô hình \"nhớ\" thông tin từ các bước trước đó\n",
    "- Truyền gradient qua thời gian (BPTT - Backpropagation Through Time)\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Dữ liệu dạng chuỗi (văn bản, thời gian, âm thanh)\n",
    "  - Cần nắm bắt phụ thuộc thời gian\n",
    "  - Độ dài đầu vào thay đổi\n",
    "  - Cần \"nhớ\" thông tin trước đó\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Huấn luyện chậm do tính tuần tự\n",
    "  - Vấn đề gradient biến mất/bùng nổ\n",
    "  - Khó nắm bắt phụ thuộc rất dài (LSTM/GRU đỡ hơn)\n",
    "  - Đã bị Transformer vượt qua trong nhiều tác vụ NLP\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Xử lý ngôn ngữ tự nhiên (trước Transformer)\n",
    "- Dự báo chuỗi thời gian\n",
    "- Phân tích cảm xúc\n",
    "- Nhận dạng giọng nói\n",
    "- Sinh nhạc, văn bản\n",
    "\n",
    "## 4. Transformer\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Encoder-Decoder với Self-Attention\n",
    "- **Thành phần chính**:\n",
    "  - Multi-head Self-Attention: cho phép mô hình tập trung vào các phần khác nhau\n",
    "  - Position Encoding: đưa thông tin vị trí vào mô hình\n",
    "  - Feed-Forward Networks: xử lý từng vị trí độc lập\n",
    "  - Layer Normalization và Residual Connections\n",
    "- **Biến thể quan trọng**: BERT, GPT, T5, ViT (Vision Transformer)\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Thay thế xử lý tuần tự bằng cơ chế attention song song\n",
    "- Sử dụng self-attention để nắm bắt mối quan hệ giữa các phần tử\n",
    "- Mỗi phần tử có thể tương tác trực tiếp với tất cả phần tử khác\n",
    "- Encoder nắm bắt ngữ cảnh bidirectional, Decoder tạo đầu ra tự hồi quy\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Bài toán NLP (dịch máy, tóm tắt, phân loại văn bản)\n",
    "  - Cần nắm bắt mối quan hệ toàn cục giữa các phần từ xa\n",
    "  - Đủ tài nguyên tính toán và dữ liệu lớn\n",
    "  - Cần state-of-the-art performance\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Độ phức tạp O(n²) theo độ dài chuỗi\n",
    "  - Đòi hỏi nhiều dữ liệu và tài nguyên tính toán\n",
    "  - Cần kỹ thuật đặc biệt cho chuỗi dài\n",
    "  - Mô hình thường rất lớn\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Dịch máy\n",
    "- Mô hình ngôn ngữ lớn (LLM)\n",
    "- Tóm tắt văn bản\n",
    "- Trả lời câu hỏi\n",
    "- Phân tích cảm xúc\n",
    "- Vision Transformer cho xử lý ảnh\n",
    "\n",
    "## 5. Generative Adversarial Networks (GAN)\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Hai mạng đấu tranh - Generator và Discriminator\n",
    "- **Generator**: Tạo dữ liệu giả từ nhiễu ngẫu nhiên\n",
    "- **Discriminator**: Phân biệt dữ liệu thật/giả\n",
    "- **Biến thể quan trọng**: DCGAN, StyleGAN, CycleGAN, Pix2Pix, BigGAN\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Đào tạo song song hai mạng với mục tiêu đối lập\n",
    "- Generator cố gắng tạo dữ liệu đánh lừa Discriminator\n",
    "- Discriminator cố gắng phân biệt dữ liệu thật/giả chính xác\n",
    "- Zero-sum game: Generator được cải thiện khi Discriminator bị đánh lừa\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Cần tạo dữ liệu mới chất lượng cao\n",
    "  - Có dữ liệu huấn luyện chất lượng tốt\n",
    "  - Cần mô phỏng phân phối dữ liệu phức tạp\n",
    "  - Bài toán chuyển đổi domain (domain translation)\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Khó huấn luyện, bất ổn định\n",
    "  - Mode collapse (sinh ra ít mẫu đa dạng)\n",
    "  - Đánh giá hiệu suất khó khăn\n",
    "  - Tốn kém tài nguyên tính toán\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Tạo hình ảnh chân thực\n",
    "- Chuyển đổi hình ảnh (image-to-image translation)\n",
    "- Tăng cường dữ liệu (data augmentation)\n",
    "- Super-resolution\n",
    "- Tổng hợp khuôn mặt, giọng nói\n",
    "- Thiết kế thuốc, vật liệu\n",
    "\n",
    "## 6. Autoencoder\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Encoder → Latent Space → Decoder\n",
    "- **Encoder**: Nén dữ liệu thành biểu diễn thấp chiều (latent representation)\n",
    "- **Decoder**: Tái tạo dữ liệu gốc từ biểu diễn latent\n",
    "- **Biến thể quan trọng**: \n",
    "  - Variational Autoencoder (VAE): thêm ràng buộc xác suất cho latent space\n",
    "  - Denoising Autoencoder: tái tạo dữ liệu sạch từ dữ liệu nhiễu\n",
    "  - Sparse Autoencoder: áp đặt tính thưa thớt lên latent space\n",
    "  - Contractive Autoencoder: tăng tính ổn định của biểu diễn\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Học biểu diễn dữ liệu không giám sát\n",
    "- Tối thiểu hóa reconstruction error\n",
    "- VAE học một phân phối xác suất cho latent space\n",
    "- Nén thông tin thành các đặc trưng thiết yếu nhất\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Cần giảm chiều dữ liệu\n",
    "  - Phát hiện bất thường (anomaly detection)\n",
    "  - Học biểu diễn không giám sát\n",
    "  - Cần tạo dữ liệu với điều kiện nhất định (VAE)\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Biểu diễn có thể không phân tách tốt các lớp\n",
    "  - VAE thường tạo ra kết quả mờ (blurry)\n",
    "  - Khó đánh giá chất lượng biểu diễn học được\n",
    "  - Cần tinh chỉnh kiến trúc cho từng loại dữ liệu\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Giảm chiều dữ liệu\n",
    "- Phát hiện bất thường\n",
    "- Loại bỏ nhiễu (denoising)\n",
    "- Sinh dữ liệu có điều kiện (VAE)\n",
    "- Hoàn thiện dữ liệu bị thiếu (image inpainting)\n",
    "- Nén dữ liệu\n",
    "\n",
    "## 7. Vision Transformer (ViT)\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Image patching → Linear embedding → Transformer Encoder\n",
    "- **Thành phần chính**:\n",
    "  - Patch Embedding: chia nhỏ ảnh thành các patch và embedding\n",
    "  - Position Embedding: thêm thông tin vị trí\n",
    "  - Transformer Encoder: xử lý các patch như tokens trong NLP\n",
    "  - MLP Head: layer cuối dùng cho phân loại\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Chia ảnh thành các patch không chồng lấp\n",
    "- Áp dụng kiến trúc Transformer từ NLP cho các patch\n",
    "- Self-attention giữa tất cả các patch\n",
    "- Không sử dụng convolution, pooling như CNN truyền thống\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Có lượng dữ liệu huấn luyện lớn\n",
    "  - Đủ tài nguyên tính toán\n",
    "  - Cần hiệu suất cao nhất\n",
    "  - Cần nắm bắt mối quan hệ toàn cục trong ảnh\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Tốn kém tính toán với ảnh độ phân giải cao\n",
    "  - Cần nhiều dữ liệu hơn CNN để đạt hiệu quả tương đương\n",
    "  - Thiếu inductive bias phù hợp cho xử lý ảnh\n",
    "  - Khó triển khai trên thiết bị yếu\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Phân loại ảnh\n",
    "- Phát hiện đối tượng\n",
    "- Phân đoạn ảnh\n",
    "- Ước tính tư thế (pose estimation)\n",
    "- Transfer learning cho các tác vụ thị giác máy tính\n",
    "\n",
    "## 8. Graph Neural Networks (GNN)\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Các layer xử lý thông tin giữa các node trong đồ thị\n",
    "- **Thành phần chính**:\n",
    "  - Node embeddings: biểu diễn vector của các node\n",
    "  - Message passing: cập nhật thông tin giữa các node kề nhau\n",
    "  - Graph pooling: tổng hợp thông tin toàn đồ thị\n",
    "  - Readout function: tạo biểu diễn đồ thị toàn cục\n",
    "\n",
    "- **Biến thể quan trọng**:\n",
    "  - Graph Convolutional Network (GCN)\n",
    "  - Graph Attention Network (GAT)\n",
    "  - GraphSAGE\n",
    "  - Graph Isomorphism Network (GIN)\n",
    "\n",
    "### Cơ chế mô hình\n",
    "- Học biểu diễn cho các node, edge và toàn bộ đồ thị\n",
    "- Lan truyền thông tin giữa các node kề nhau\n",
    "- Kết hợp đặc trưng node và cấu trúc liên kết\n",
    "- Giữ tính bất biến với thứ tự node (permutation invariant)\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Dữ liệu có cấu trúc đồ thị/mạng\n",
    "  - Cần nắm bắt mối quan hệ giữa các thực thể\n",
    "  - Làm việc với dữ liệu không thuần nhất (heterogeneous)\n",
    "  - Cần biểu diễn cả node và cấu trúc kết nối\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Khó xử lý đồ thị rất lớn\n",
    "  - Vấn đề over-smoothing sau nhiều layer\n",
    "  - Tốn kém tính toán cho đồ thị dày đặc\n",
    "  - Khó áp dụng nhiều layer so với CNN/RNN\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Dự đoán liên kết trong mạng xã hội\n",
    "- Phát hiện gian lận/bất thường\n",
    "- Khoa học phân tử, thiết kế thuốc\n",
    "- Hệ thống gợi ý\n",
    "- Dự báo giao thông\n",
    "- Phân tích mạng lưới diện rộng\n",
    "\n",
    "## 9. Diffusion Models\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: U-Net với attention hoặc Transformer-based backbone\n",
    "- **Thành phần chính**:\n",
    "  - Noise predictor/denoiser: dự đoán nhiễu đã thêm vào\n",
    "  - Time/step embedding: cung cấp thông tin về bước nhiễu\n",
    "  - Cross-attention (cho models có điều kiện)\n",
    "  \n",
    "### Cơ chế mô hình\n",
    "- **Forward process**: Thêm nhiễu Gaussian dần dần vào dữ liệu\n",
    "- **Reverse process**: Học cách loại bỏ nhiễu từng bước nhỏ\n",
    "- Tạo dữ liệu bằng cách bắt đầu từ nhiễu hoàn toàn và dần \"khử nhiễu\"\n",
    "- Có thể thêm điều kiện (text, class) thông qua cross-attention\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Cần tạo dữ liệu chất lượng cao\n",
    "  - Muốn kiểm soát quá trình tạo\n",
    "  - Sinh dữ liệu có điều kiện (text-to-image)\n",
    "  - Cần độ đa dạng tốt hơn so với GAN\n",
    "  \n",
    "- **Hạn chế**:\n",
    "  - Quá trình sampling chậm (cần nhiều bước)\n",
    "  - Tốn kém tính toán khi huấn luyện và sinh dữ liệu\n",
    "  - Cần tinh chỉnh lịch trình nhiễu (noise schedule)\n",
    "  - Mô hình thường rất lớn\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Tạo hình ảnh chất lượng cao (Stable Diffusion, DALLE)\n",
    "- Text-to-image generation\n",
    "- Chỉnh sửa ảnh (image editing)\n",
    "- Tạo âm thanh, nhạc\n",
    "- Super-resolution\n",
    "- Hoàn thiện dữ liệu bị thiếu (inpainting)\n",
    "\n",
    "## 10. Self-Supervised Models\n",
    "\n",
    "### Kiến trúc\n",
    "- **Cấu trúc cơ bản**: Encoder (+ Decoder tùy thuộc vào task)\n",
    "- **Biến thể quan trọng**:\n",
    "  - Contrastive learning models (SimCLR, MoCo)\n",
    "  - Masked Autoencoder (MAE)\n",
    "  - BERT, GPT (cho NLP)\n",
    "  - CLIP (multi-modal)\n",
    "  \n",
    "### Cơ chế mô hình\n",
    "- Tạo tác vụ giả (pretext tasks) từ dữ liệu không nhãn\n",
    "- Học biểu diễn chung (representations) mà không cần nhãn\n",
    "- Contrastive learning: tối đa hóa sự tương đồng giữa các augmentation của cùng mẫu\n",
    "- Masked prediction: dự đoán phần bị che của đầu vào\n",
    "\n",
    "### Khi nào nên dùng\n",
    "- **Nên dùng khi**:\n",
    "  - Có nhiều dữ liệu không nhãn, ít dữ liệu có nhãn\n",
    "  - Cần biểu diễn tổng quát cho nhiều tác vụ downstream\n",
    "  - Transfer learning\n",
    "  - Cải thiện khả năng mô hình với dữ liệu ít\n",
    "\n",
    "- **Hạn chế**:\n",
    "  - Có thể tốn kém tính toán khi pre-train\n",
    "  - Thiết kế pretext task phù hợp là khó\n",
    "  - Có thể cần fine-tuning cho tác vụ cụ thể\n",
    "  - Chất lượng phụ thuộc vào kỹ thuật data augmentation\n",
    "\n",
    "### Ứng dụng mạnh mẽ\n",
    "- Pre-training cho tác vụ computer vision\n",
    "- Pre-training cho NLP\n",
    "- Representation learning\n",
    "- Few-shot/zero-shot learning\n",
    "- Cross-modal learning (text-image)\n",
    "- Xử lý dữ liệu không nhãn quy mô lớn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
